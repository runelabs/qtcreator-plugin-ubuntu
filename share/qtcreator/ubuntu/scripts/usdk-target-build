#!/usr/bin/env python3
# Copyright (C) 2016 Canonical Ltd.
# Authors: Colin Watson <cjwatson@ubuntu.com>,
#          Brian Murray <brian@ubuntu.com>
#          Michael Vogt <mvo@ubuntu.com>
#          Benjamin Zeller <benjamin.zeller@canonical.com>
#          Zolt√°n Balogh <zoltan.balogh@canonical.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; version 3 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import print_function

try:
    from urllib.error import URLError
    from urllib.request import urlopen
except ImportError:
    from urllib2 import URLError, urlopen
import os
import pwd
import re
import shutil
import stat
import subprocess
import sys
import argparse
import time
import hashlib
from textwrap import dedent
from xml.etree import ElementTree
import json
import os.path
from time import gmtime, strftime

framework_base = {
    # 15.04
    "ubuntu-sdk-15.04-html": "ubuntu-sdk-15.04",
    "ubuntu-sdk-15.04-papi": "ubuntu-sdk-15.04",
    "ubuntu-sdk-15.04-qml": "ubuntu-sdk-15.04",
    # 15.10
    "ubuntu-sdk-15.10-html-dev1": "ubuntu-sdk-15.10-dev1",
    "ubuntu-sdk-15.10-papi-dev1": "ubuntu-sdk-15.10-dev1",
    "ubuntu-sdk-15.10-qml-dev1": "ubuntu-sdk-15.10-dev1",
    }


framework_series = {
    "ubuntu-sdk-15.04": "vivid",
    "ubuntu-sdk-15.10": "wily",
    "ubuntu-sdk-16.04": "xenial",
    "ubuntu-sdk-16.10": "yakketi",
    }

extra_packages = {
    "ubuntu-sdk-15.04": [
        "ubuntu-sdk-libs:{TARGET}",
        "ubuntu-sdk-libs-dev:{TARGET}",
        "ubuntu-sdk-libs-tools",
        "oxideqt-codecs-extra",
        "ubuntu-html5-container:{TARGET}",
        "qt5-doc",
        "language-pack-en",
        ],
    "ubuntu-sdk-15.10-dev1": [
        "ubuntu-sdk-libs:{TARGET}",
        "ubuntu-sdk-libs-dev:{TARGET}",
        "ubuntu-sdk-libs-tools",
        "oxideqt-codecs-extra",
        "qt5-doc",
        "language-pack-en",
        ],
    "ubuntu-sdk-16.04": [
        "ubuntu-sdk-libs-tools",
        "oxideqt-codecs-extra",
        "qt5-doc",
        "language-pack-en",
        "libcontent-hub0:{TARGET}",
        "libjsoncpp1:{TARGET}",
        "libnet-cpp2:{TARGET}",
        "libprocess-cpp3:{TARGET}",
        "libqt5keychain0:{TARGET}",
        "libqt5multimedia5-plugins:{TARGET}",
        "libqt5sql5-sqlite:{TARGET}",
        "qml-module-qt-labs-folderlistmodel:{TARGET}",
        "qml-module-qt-labs-settings:{TARGET}",
        "qml-module-qt-websockets:{TARGET}",
        "qml-module-qtbluetooth:{TARGET}",
        "qml-module-qtgraphicaleffects:{TARGET}",
        "qml-module-qtlocation:{TARGET}",
        "qml-module-qtmultimedia:{TARGET}",
        "qml-module-qtorganizer:{TARGET}",
        "qml-module-qtpositioning:{TARGET}",
        "qml-module-qtpurchasing:{TARGET}",
        "qml-module-qtqml-models2:{TARGET}",
        "qml-module-qtqml-statemachine:{TARGET}",
        "qml-module-qtquick-layouts:{TARGET}",
        "qml-module-qtquick-localstorage:{TARGET}",
        "qml-module-qtquick-particles2:{TARGET}",
        "qml-module-qtquick-window2:{TARGET}",
        "qml-module-qtquick-xmllistmodel:{TARGET}",
        "qml-module-qtquick2:{TARGET}",
        "qml-module-qtsensors:{TARGET}",
        "qml-module-ubuntu-onlineaccounts:{TARGET}",
        "qml-module-ubuntu-onlineaccounts-client:{TARGET}",
        "qt5-image-formats-plugins:{TARGET}",
        "qtdeclarative5-poppler1.0:{TARGET}",
        "qtdeclarative5-u1db1.0:{TARGET}",
        "qtdeclarative5-ubuntu-content1:{TARGET}",
        "qtdeclarative5-ubuntu-download-manager0.1:{TARGET}",
        "qtdeclarative5-ubuntu-mediascanner0.1:{TARGET}",
        "qtdeclarative5-ubuntu-push-plugin:{TARGET}",
        "qtdeclarative5-ubuntu-syncmonitor0.1:{TARGET}",
        "qtdeclarative5-ubuntu-telephony-phonenumber0.1:{TARGET}",
        "qtdeclarative5-ubuntu-ui-toolkit-plugin:{TARGET}",
        "qtdeclarative5-usermetrics0.1:{TARGET}",
        "ubuntu-ui-toolkit-theme:{TARGET}",
        "qtdeclarative5-ubuntu-ui-toolkit-plugin:{TARGET}",
        "google-mock:{TARGET}",
        "libcontent-hub-dev:{TARGET}",
        "libjsoncpp-dev:{TARGET}",
        "libnet-cpp-dev:{TARGET}",
        "libprocess-cpp-dev:{TARGET}",
        "libproperties-cpp-dev:{TARGET}",
        "libqt5sensors5-dev:{TARGET}",
        "libqt5svg5-dev:{TARGET}",
        "libqt5websockets5-dev:{TARGET}",
        "libqt5xmlpatterns5-dev:{TARGET}",
        "libssl-dev:{TARGET}",
        "libunity-scopes-dev:{TARGET}",
        "qt3d5-dev:{TARGET}",
        "qt5-default:{TARGET}",
        "qtbase5-dev:{TARGET}",
        "qtdeclarative5-dev:{TARGET}",
        "qtdeclarative5-dev-tools:{TARGET}",
        "qtlocation5-dev:{TARGET}",
        "qtmultimedia5-dev:{TARGET}",
        "qtpim5-dev:{TARGET}",
        "qttools5-dev:{TARGET}",
        "ubuntu-sdk-qmake-extras:{TARGET}",
        "ubuntu-ui-toolkit-doc:{TARGET}",
        "snapcraft"
       ],
    "ubuntu-sdk-16.10": [
        ]
    }

# all runtime only packages, they are only installed on NON cross chroots
runtime_packages = [
    "unity-scope-tool",
    "ssh",
    "gdbserver",
    "pulseaudio",
    "gstreamer1.0-pulseaudio",
    "gstreamer1.0-plugins-good",
    "gstreamer0.10-pulseaudio",
    "gstreamer0.10-plugins-good",
    "qml-module-ubuntu-connectivity",
    "webapp-container"
]

metadata_template = """\
architecture: {ARCH}
creation_date: {CREATETIME}
properties:
  architecture: {ARCH}
  description: {FULLNAME}
  name: {FULLNAME}
  os: ubuntu
  release: {SERIES}
  variant: default
templates:
  "/etc/hostname":
    template: hostname.tpl
    when:
    - create
  "/etc/hosts":
    template: hosts.tpl
    when:
    - create
"""

network_settings = """\
# This file describes the network interfaces available on your system
# and how to activate them. For more information, see interfaces(5).

# The loopback network interface
auto lo
iface lo inet loopback

auto eth0
iface eth0 inet dhcp
"""

primary_arches = ["amd64", "i386"]
lxd_arch = {
    "i386": "i686",
    "amd64": "x86_64",
    "armhf": "armv7l",
    "arm64": "aarch64",
    "powerpc": "ppc",
    "ppc64el": "ppc64le"
}

# list of target architecures supported by host architectures
compatible_arches = {
    "i386": ["i386", "armhf"],
    "amd64": ["i386", "amd64", "armhf", "arm64"],
    "armhf": ["armhf"],
    "arm64": ["arm64"],
}

non_meta_re = re.compile(r'^[a-zA-Z0-9+,./:=@_-]+$')
GEOIP_SERVER = "http://geoip.ubuntu.com/lookup"
overlay_ppa = "ci-train-ppa-service/stable-phone-overlay"
rootfs = "rootfs"
qemu_arm_static = "/usr/bin/qemu-arm-static"

template_directory = "templates"
hostname_tpl_filename = "hostname.tpl"
hostname_tpl = "{{ container.name }}"
hosts_tpl_filename = "hosts.tpl"
hosts_tpl = "127.0.0.1   localhost\
             \n127.0.1.1   {{ container.name }}\
             \n# The following lines are desirable for IPv6 capable hosts\
             \n::1     ip6-localhost ip6-loopback\
             \nfe00::0 ip6-localnet\
             \nff00::0 ip6-mcastprefix\
             \nff02::1 ip6-allnodes\
             \nff02::2 ip6-allrouters"
upstart_override_tpl_filename = "upstart-override.tpl"
upstart_override_tpl = "manual"


class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'

    def disable(self):
        self.HEADER = ''
        self.OKBLUE = ''
        self.OKGREEN = ''
        self.WARNING = ''
        self.FAIL = ''
        self.ENDC = ''


def make_md5_sha256(file_name, combined_hash_sha256):
    hash_md5 = hashlib.md5()
    hash_sha256 = hashlib.sha256()
    with open(file_name, "rb") as f:
        for chunk in iter(lambda: f.read(65536), b""):
            hash_sha256.update(chunk)
            hash_md5.update(chunk)
            combined_hash_sha256.update(chunk)
    return (hash_md5.hexdigest(),
            hash_sha256.hexdigest(),
            combined_hash_sha256.hexdigest())


def add_image_to_download(framework, base_arch, target_arch, image_type):
    match = re.search('ubuntu-sdk-(.*)', framework)
    if match:
        ubuntu_version = match.group(1)
    series = framework_series[framework]
    root_image = "%s-%s-%s-root.tar.xz" % (framework, base_arch, target_arch)
    lxd_image = "%s-%s-%s-lxd.tar.xz" % (framework, base_arch, target_arch)
    if not os.path.isfile(root_image):
        print("The %s root file does not exist" % root_image)
        return
    if not os.path.isfile(lxd_image):
        print("The %s lxd file does not exist" % lxd_image)
        return
    str_time = strftime("%a, %d %b %Y %H:%M:%S %z", gmtime())
    short_date = strftime("%Y%m%d", gmtime())
    combined_hash_sha256 = hashlib.sha256()
    lxd_md5,\
        lxd_sha256,\
        combined_sha256 = make_md5_sha256(lxd_image, combined_hash_sha256)
    root_md5,\
        root_sha256,\
        combined_sha256 = make_md5_sha256(root_image, combined_hash_sha256)
    download_json = "com.ubuntu.sdkimage:released:download.json"
    index_json = "index.json"
    license = "http://www.canonical.com/intellectual-property-policy"
    image_category = "com.ubuntu.sdk-image:released:download"
    download_json_path = "streams/v1/%s" % download_json
    download_template = '{"content_id" : \
                          "com.ubuntu.sdk-image:released:download",\
                          "datatype" : "image-downloads",\
                          "format" : "products:1.0",\
                          "license" : "%s",\
                          "products" : "",\
                          "updated" : "%s"}' % (license, str_time)
    index_template = '{"index": {\
                           "com.ubuntu.sdk-image:released:download": {\
                               "datatype": "image-downloads",\
                               "path": "%s",\
                               "updated": "%s",\
                               "products": [],\
                               "format": "products:1.0"\
                              }\
                          },\
                      "updated": "%s",\
                      "format": "index:1.0"\
                      }' % (download_json_path, str_time, str_time)
    if os.path.isfile(download_json):
        with open(download_json) as download_json_file:
            download_data = json.load(download_json_file)
    else:
        download_data = json.loads(download_template)
    if os.path.isfile(index_json):
        with open(index_json) as index_json_file:
            index_data = json.load(index_json_file)
    else:
        index_data = json.loads(index_template)
    products = download_data["products"]
    pruduct_id = "com.ubuntu.sdkimage:builder:%s:%s:%s"\
                 % (base_arch, ubuntu_version, target_arch)
    if pruduct_id not in index_data["index"][image_category]["products"]:
        index_data["index"][image_category]["products"].append(pruduct_id)
    lxd_file = '{"size": %s,\
                "ftype": "lxd.tar.xz",\
                "path": "releases/%s/%s",\
                "combined_sha256": "%s",\
                "sha256": "%s",\
                "md5": "%s"\
                }'\
                % (os.path.getsize(lxd_image),
                   series,
                   lxd_image,
                   combined_sha256,
                   lxd_sha256,
                   lxd_md5)
    root_file = '{"size": %s,\
                 "ftype": "root.tar.xz",\
                 "path": "releases/%s/%s",\
                 "combined_sha256": "%s",\
                 "sha256": "%s",\
                 "md5": "%s"\
                 }' % (os.path.getsize(root_image),
                       series,
                       root_image,
                       combined_sha256,
                       root_sha256,
                       root_md5)
    items = '{"lxd.tar.xz": %s,\
              "root.tar.xz": %s\
             }' % (lxd_file, root_file)
    date_section = '{"items" : %s,\
                    "pubname": "ubuntu-%s-%s-overlay-%s-builder-%s",\
                    "label": "sdk-%s"\
                    }' % (items,
                          series,
                          ubuntu_version,
                          target_arch,
                          short_date,
                          target_arch)
    versions = '{"%s": %s\
                }' % (short_date, date_section)
    product_object = '{"versions": %s,\
                       "arch": "%s",\
                       "supported": true,\
                       "release_title": "%s",\
                       "release_codename": "%s",\
                       "version": "%s",\
                       "release": "%s",\
                       "aliases": \
                       "%s-%s-%s-%s,ubuntu-framework-%s-%s-%s-%s",\
                       "os": "ubuntu",\
                       "support_eol": "2019-04-17"\
                      }' % (versions,
                            lxd_arch[base_arch],
                            series,
                            series.capitalize(),
                            ubuntu_version,
                            ubuntu_version,
                            framework,
                            base_arch,
                            target_arch,
                            image_type,
                            ubuntu_version,
                            base_arch,
                            target_arch,
                            image_type)
    products_string = '{"%s": %s}' % (pruduct_id, product_object)
    new_product = json.loads(products_string)
    merged_products = dict(products, **new_product)
    download_data["products"] = merged_products
    download_data["updated"] = str_time
    with open(download_json, 'w') as outfile:
        json.dump(download_data, outfile, indent=4)
    index_data["updated"] = str_time
    index_data["index"][image_category]["updated"] = str_time
    with open(index_json, 'w') as outfile:
        json.dump(index_data, outfile, indent=4)


def get_geoip_country_code_prefix():
    click_no_local_mirror = os.environ.get('CLICK_NO_LOCAL_MIRROR', 'auto')
    if click_no_local_mirror == '1':
        return ""
    try:
        with urlopen(GEOIP_SERVER) as f:
            xml_data = f.read()
        et = ElementTree.fromstring(xml_data)
        cc = et.find("CountryCode")
        if not cc:
            return ""
        return cc.text.lower() + "."
    except (ElementTree.ParseError, URLError):
        pass
    return ""


def generate_sources(series, native_arch, target_arch,
                     archive_mirror, ports_mirror, components):
    """Generate a list of strings for apts sources.list.
    Arguments:
    series -- the distro series (e.g. vivid)
    native_arch -- the native architecture (e.g. amd64)
    target_arch -- the target architecture (e.g. armhf)
    archive_mirror -- main mirror, e.g. http://archive.ubuntu.com/ubuntu
    ports_mirror -- ports mirror, e.g. http://ports.ubuntu.com/ubuntu-ports
    components -- the components as string, e.g. "main restricted universe"
    """
    pockets = ['%s' % series]
    for pocket in ['updates', 'security']:
        pockets.append('%s-%s' % (series, pocket))
    sources = []
    # write binary lines
    arches = [target_arch]
    if native_arch != target_arch:
        arches.append(native_arch)
    for arch in arches:
        if arch not in primary_arches:
            mirror = ports_mirror
        else:
            mirror = archive_mirror
        for pocket in pockets:
            sources.append("deb [arch=%s] %s %s %s" %
                           (arch, mirror, pocket, components))
    # write source lines
    for pocket in pockets:
        sources.append("deb-src %s %s %s" %
                       (archive_mirror, pocket, components))
    return sources


def shell_escape(command):
    escaped = []
    for arg in command:
        if non_meta_re.match(arg):
            escaped.append(arg)
        else:
            escaped.append("'%s'" % arg.replace("'", "'\\''"))
    return " ".join(escaped)


def strip_dev_series_from_framework(framework):
    """Remove trailing -dev[0-9]+ from a framework name"""
    return re.sub(r'^(.*)-dev[0-9]+$', r'\1', framework)


class ClickChroot:

    DAEMON_POLICY = dedent("""\
    #!/bin/sh
    while true; do
        case "$1" in
          -*) shift ;;
          makedev) exit 0;;
          x11-common) exit 0;;
          *) exit 101;;
        esac
    done
    """)

    def __init__(self,
                 system_arch,
                 target_arch,
                 framework,
                 image_type,
                 series=None,
                 chroots_dir=None):
        self.target_arch = target_arch
        self.framework = strip_dev_series_from_framework(framework)
        self.image_type = image_type
        if series is None:
            series = framework_series[self.framework_base]
        self.series = series
        self.native_arch = self._get_native_arch(system_arch, self.target_arch)
        if chroots_dir is None:
            chroots_dir = os.getcwd()
        self.chroots_dir = chroots_dir
        if "SUDO_USER" in os.environ:
            self.user = os.environ["SUDO_USER"]
        elif "PKEXEC_UID" in os.environ:
            self.user = pwd.getpwuid(int(os.environ["PKEXEC_UID"])).pw_name
        else:
            self.user = pwd.getpwuid(os.getuid()).pw_name
        self.dpkg_architecture = self._dpkg_architecture()

    def _get_native_arch(self, system_arch, target_arch):
        """Determine the proper native architecture for a chroot.

        Some combinations of system and target architecture do not require
        cross-building, so in these cases we just create a chroot suitable
        for native building.
        """
        if (system_arch, target_arch) in (
                ("amd64", "i386"),
                # This will only work if the system is running a 64-bit
                # kernel; but there's no alternative since no i386-to-amd64
                # cross-compiler is available in the Ubuntu archive.
                ("i386", "amd64"),
                ):
            return target_arch
        else:
            return system_arch

    def _dpkg_architecture(self):
        dpkg_architecture = {}
        command = ["dpkg-architecture", "-a%s" % self.target_arch]
        env = dict(os.environ)
        env["CC"] = "true"
        # Force dpkg-architecture to recalculate everything rather than
        # picking up values from the environment, which will be present when
        # running the test suite under dpkg-buildpackage.
        for key in list(env):
            if key.startswith("DEB_BUILD_") or key.startswith("DEB_HOST_"):
                del env[key]
        lines = subprocess.check_output(
            command, env=env, universal_newlines=True).splitlines()
        for line in lines:
            try:
                key, value = line.split("=", 1)
            except ValueError:
                continue
            dpkg_architecture[key] = value
        if self.native_arch == self.target_arch:
            # We may have overridden the native architecture (see
            # _get_native_arch above), so we need to force DEB_BUILD_* to
            # match.
            for key in list(dpkg_architecture):
                if key.startswith("DEB_HOST_"):
                    new_key = "DEB_BUILD_" + key[len("DEB_HOST_"):]
                    dpkg_architecture[new_key] = dpkg_architecture[key]
        return dpkg_architecture

    def _generate_daemon_policy(self, mount):
        daemon_policy = "%s/usr/sbin/policy-rc.d" % mount
        with open(daemon_policy, "w") as policy:
            policy.write(self.DAEMON_POLICY)
        return daemon_policy

    def _generate_apt_proxy_file(self, mount, proxy):
        apt_conf_d = os.path.join(mount, "etc", "apt", "apt.conf.d")
        if not os.path.exists(apt_conf_d):
            os.makedirs(apt_conf_d)
        apt_conf_f = os.path.join(apt_conf_d, "99-click-chroot-proxy")
        if proxy:
            with open(apt_conf_f, "w") as f:
                f.write(dedent("""\
                // proxy settings copied by click chroot
                Acquire {
                    HTTP {
                        Proxy "%s";
                    };
                };
                """) % proxy)
        return apt_conf_f

    def _generate_finish_script(self, mount, build_pkgs):
        finish_script = "%s/finish.sh" % mount
        with open(finish_script, 'w') as finish:
            finish.write(dedent("""\
                #!/bin/bash
                set -e
                # Configure target arch
                dpkg --add-architecture {target_arch}
                # Reload package lists
                apt-get update || true
                # Pull down signature requirements
                apt-get -y --force-yes install gnupg ubuntu-keyring
            """).format(target_arch=self.target_arch))
            if self.series == "vivid" or self.series == "xenial":
                finish.write(dedent("""\
                    apt-get -y --force-yes install software-properties-common
                    add-apt-repository -y ppa:{ppa}
                    echo "Package: *"  \
                        > /etc/apt/preferences.d/stable-phone-overlay.pref
                    echo \
                        "Pin: release o=LP-PPA-{pin_ppa}" \
                        >> /etc/apt/preferences.d/stable-phone-overlay.pref
                    echo "Pin-Priority: 1001" \
                        >> /etc/apt/preferences.d/stable-phone-overlay.pref
                """).format(ppa=overlay_ppa,
                            pin_ppa=re.sub('/', '-', overlay_ppa)))
            finish.write(dedent("""\
                # Reload package lists
                apt-get update || true
                # Disable debconf questions
                # so that automated builds won't prompt
                echo set debconf/frontend Noninteractive | debconf-communicate
                echo set debconf/priority critical | debconf-communicate
                apt-get -y --force-yes dist-upgrade
                # Install basic build tool set to match buildd
                apt-get -y --force-yes install {build_pkgs}
                # Make sure network is initialized
                systemctl enable systemd-networkd.service
                # Make sure dpkg variables are correct
                for i in $(dpkg-architecture -a {target_arch} 2>/dev/null); \
                    do echo "export $i" >> /etc/profile.d/clickvars.sh ; \
                done
                echo "if [ ! -z \\"\\${{SSH_CONNECTION}}\\" ]; then" >> /etc/profile.d/clickvars.sh ;
                echo "    IP=(\\$SSH_CONNECTION)" >> /etc/profile.d/clickvars.sh ;
                echo "    export PULSE_SERVER=\\${{IP[0]}}" >> /etc/profile.d/clickvars.sh ;
                echo "fi" >> /etc/profile.d/clickvars.sh ;
                # enable pulsed streaming
                if [ -e "/etc/pulse/default.pa" ]; then
                    sed "s/^#load-module module-native-protocol-tcp$/load-module module-native-protocol-tcp/g" -i /etc/pulse/default.pa
                fi
                # Clean up
                rm /finish.sh
                apt-get clean
                [[ -e /sbin/initctl_tmp ]] && \
                mv /sbin/initctl_tmp /sbin/initctl
                rm /usr/sbin/policy-rc.d
            """).format(build_pkgs=' '.join(build_pkgs),
                        target_arch=self.target_arch))
        return finish_script

    def _debootstrap(self, components, mount, archive_mirror, ports_mirror):
        if self.native_arch in primary_arches:
            mirror = archive_mirror
            subprocess.check_call([
                "debootstrap",
                "--arch", self.native_arch,
                "--variant=buildd",
                "--components=%s" % ','.join(components),
                self.series,
                mount,
                mirror
                ])
        else:
            mirror = ports_mirror
            subprocess.check_call([
                "debootstrap",
                "--arch", self.native_arch,
                "--foreign",
                "--variant=buildd",
                "--components=%s" % ','.join(components),
                self.series,
                mount,
                mirror
                ])

    @property
    def framework_base(self):
        if self.framework in framework_base:
            return framework_base[self.framework]
        else:
            return self.framework

    @property
    def full_name(self):
        return "%s-%s-%s" % (self.framework_base,
                             self.native_arch,
                             self.target_arch)

    def _make_executable(self, path):
        mode = stat.S_IMODE(os.stat(path).st_mode)
        os.chmod(path, mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)

    def _make_cross_package(self, prefix):
        if self.native_arch == self.target_arch:
            return prefix
        else:
            target_tuple = self.dpkg_architecture["DEB_HOST_GNU_TYPE"]
            return "%s-%s" % (prefix, target_tuple)

    def _is_crossbuild(self):
        return (self.native_arch != self.target_arch)

    def create(self):
        components = ["main", "restricted", "universe", "multiverse"]
        mount = "%s/%s" % (os.getcwd(), rootfs)
        proxy = None
        if not proxy and "http_proxy" in os.environ:
            proxy = os.environ["http_proxy"]
        if not proxy:
            proxy = subprocess.check_output(
                'unset x; eval "$(apt-config shell x Acquire::HTTP::Proxy)"; \
                 echo "$x"',
                shell=True, universal_newlines=True).strip()
        build_pkgs = [
            # sort alphabetically
            "apt-utils",
            "build-essential",
            "cmake",
            "dpkg-cross",
            "fakeroot",
            "libc-dev:%s" % self.target_arch,
            # build pkg names dynamically
            self._make_cross_package("g++"),
            self._make_cross_package("pkg-config"),
        ]
        for package in extra_packages.get(self.framework_base, []):
            package = package.format(TARGET=self.target_arch)
            build_pkgs.append(package)
        if not self._is_crossbuild():
            for package in runtime_packages:
                package = package.format(TARGET=self.target_arch)
                build_pkgs.append(package)
        if not os.path.exists(mount):
            os.makedirs(mount)
        else:
            print("The " +
                  bcolors.FAIL +
                  "%s" % mount +
                  bcolors.ENDC +
                  " directory already exists")
            sys.exit(1)
        country_code = get_geoip_country_code_prefix()
        archive_mirror = "http://%sarchive.ubuntu.com/ubuntu" % country_code
        ports_mirror = "http://%sports.ubuntu.com/ubuntu-ports" % country_code
        # this doesn't work because we are running this under sudo
        if 'DEBOOTSTRAP_MIRROR' in os.environ:
            archive_mirror = os.environ['DEBOOTSTRAP_MIRROR']
        self._debootstrap(components, mount, archive_mirror, ports_mirror)
        # in case of creating foreign arch image we need to add the emulator
        if self.native_arch not in primary_arches:
            if os.path.isfile(qemu_arm_static):
                shutil.copy2(qemu_arm_static, "%s/usr/bin/" % mount)
            else:
                print(bcolors.FAIL +
                      "The %s is not present, please install\
                      qemu-user-static package"
                      % qemu_arm_static +
                      bcolors.ENDC)
                sys.exit(1)
            ret_code = subprocess.call(["/usr/sbin/chroot",
                                        mount,
                                        "/debootstrap/debootstrap",
                                        "--second-stage"])
            if ret_code != 0:
                print(bcolors.FAIL +
                      "Second stage of the debootstrapping failed." +
                      bcolors.ENDC)
                sys.exit(1)
        sources = generate_sources(self.series, self.native_arch,
                                   self.target_arch,
                                   archive_mirror, ports_mirror,
                                   ' '.join(components))
        with open("%s/etc/apt/sources.list" % mount, "w") as sources_list:
            for line in sources:
                print(line, file=sources_list)
        daemon_policy = self._generate_daemon_policy(mount)
        self._make_executable(daemon_policy)
        initctl = "%s/sbin/initctl" % mount
        if os.path.exists(initctl):
            shutil.copyfile(initctl, initctl + "_tmp")
            os.remove(initctl)
            os.symlink("%s/bin/true" % mount, initctl)
        self._generate_apt_proxy_file(mount, proxy)
        finish_script = self._generate_finish_script(mount, build_pkgs)
        self._make_executable(finish_script)
        ret_code = subprocess.call(["/usr/sbin/chroot", mount, "/finish.sh"])
        if ret_code != 0:
            print(bcolors.FAIL +
                  "Debootstrapping the chroot failed." +
                  bcolors.ENDC)
            sys.exit(1)
        metadata = metadata_template.format(
            ARCH=lxd_arch[self.native_arch],
            CREATETIME=int(time.time()),
            FULLNAME=self.full_name,
            SERIES=self.series
        )
        with open("metadata.yaml", "w") as metadata_file:
                print(metadata, file=metadata_file)
        # make sure /tmp is not cleaned when the chroot boots
        with open("%s/etc/tmpfiles.d/tmp.conf" % mount,
                  "w") as notmpclean_file:
            print("d /tmp 1777 root root -", file=notmpclean_file)
        # boot up network
        with open("%s/etc/network/interfaces" % mount, "w") as network_file:
            print(network_settings, file=network_file)
        # setup sshd for running and debugging
        if not self._is_crossbuild():
            with open("%s/etc/ssh/sshd_config" % mount, "a") as sshd_conf_file:
                print("\nAuthorizedKeysFile /etc/ssh/authorized_keys.d/%u",
                      file=sshd_conf_file)
        if not os.path.exists(template_directory):
            os.makedirs(template_directory)
        print("%s/%s" % (template_directory, hostname_tpl_filename))
        with open("%s/%s" % (template_directory,
                  hostname_tpl_filename),
                  "w") as hostname_tpl_file:
                print(hostname_tpl, file=hostname_tpl_file)
        with open("%s/%s" % (template_directory,
                  hosts_tpl_filename),
                  "w") as hosts_tpl_file:
                print(hosts_tpl, file=hosts_tpl_file)

        with open("%s/%s" % (template_directory,
                  upstart_override_tpl_filename),
                  "w") as upstart_override_tpl_file:
                print(upstart_override_tpl, file=upstart_override_tpl_file)
        print("Packaging the LXD image.....")
        rootfs_parts = os.listdir(rootfs)
        ret = subprocess.call(["tar",
                               "-C",
                               "%s" % rootfs,
                               "-ScpJf",
                               "%s-root.tar.xz"
                               % self.full_name] + rootfs_parts)
        ret = subprocess.call(["tar",
                               "-ScpJf",
                               "%s-lxd.tar.xz" % self.full_name,
                               "metadata.yaml",
                               "templates"])
        print("Clean up the build artifacts.")
        shutil.rmtree(rootfs)
        shutil.rmtree("templates")
        os.remove("metadata.yaml")
        print("Create the download.json")
        add_image_to_download(self.framework,
                              self.native_arch,
                              self.target_arch,
                              self.image_type)
        sys.exit(ret)


def check_valid_arch(value):
    valid_arch_set = ["i386", "amd64", "armhf", "arm64"]
    if value not in valid_arch_set:
        raise argparse.ArgumentTypeError("%s is not a valid arch type" % value)
    return value


def check_valid_framework(value):
    if value not in framework_series:
        raise argparse.ArgumentTypeError("%s is not a valid arch type" % value)
    return value


def check_valid_type(value):
    ota_re = '^ota\d+$|^dev$'
    if not re.search(ota_re, value):
        raise argparse.ArgumentTypeError("%s is not a valid image type"
                                         % value)
    return value


def main():
    if os.geteuid() != 0:
        exit("You need to have" +
             bcolors.FAIL +
             " root privileges" +
             bcolors.ENDC +
             " to run this tool.\nPlease try again, using 'sudo'")

    parser = argparse.ArgumentParser(description="Ubuntu SDK target builder")
    parser.add_argument('-a',
                        '--target_architecture',
                        action="store",
                        default="armhf",
                        type=check_valid_arch)
    parser.add_argument('-b',
                        '--base_architecture',
                        action="store",
                        default="amd64",
                        type=check_valid_arch)
    parser.add_argument('-f',
                        '--framework',
                        action='store',
                        default="ubuntu-sdk-15.04",
                        type=check_valid_framework)
    parser.add_argument('-t',
                        '--image_type',
                        action='store',
                        default="dev",
                        type=check_valid_type)
    options = parser.parse_args()
    if os.isatty(sys.stdout.fileno()):
        print("Building " +
              bcolors.OKGREEN +
              options.image_type +
              bcolors.ENDC +
              " type image for " +
              bcolors.OKGREEN +
              options.target_architecture +
              bcolors.ENDC +
              " on " +
              bcolors.OKGREEN +
              options.base_architecture + bcolors.ENDC +
              " base arch with " + bcolors.OKGREEN +
              options.framework + bcolors.ENDC +
              " framework")
    else:
        bcolors.disable()
    click = ClickChroot(options.base_architecture,
                        options.target_architecture,
                        options.framework,
                        options.image_type,
                        None,
                        os.getcwd())
    sys.exit(click.create())

main()
